{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PV Production Classification with Logistic Regression\n",
    "\n",
    "Multi-class logistic regression model to classify PV production levels based on weather conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_excel('Data/RawData.xlsx')\n",
    "\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "print(f\"\\nColumns: {data.columns.tolist()}\")\n",
    "print(f\"\\nFirst rows:\\n{data.head()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Data Preprocessing\n",
    "\n",
    "We classify PV production into 3 classes based on percentiles: Low (0-33%), Medium (33-66%), High (66-100%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Filter out zero production values\ndata_filtered = data[data['electricity_kW'] > 0].copy()\n\nprint(f\"Original dataset: {len(data)} samples\")\nprint(f\"After filtering zeros: {len(data_filtered)} samples\")\n\n# Extract features (X) and target (y)\nX = data_filtered[['Temperature_celcius', 'Rain_mm_per_h', 'Snow_mm_per_h', \n          'Air density_kg_per_m3', 'Ground_level_solar_irradiance_W_per_m2', \n          'Cloud_cover_fraction', 'wind_speed_m_per_s']].values\n\ny_continuous = data_filtered['electricity_kW'].values\n\n# Create classes based on percentiles\npercentile_33 = np.percentile(y_continuous, 33)\npercentile_66 = np.percentile(y_continuous, 66)\n\nprint(f\"\\nLow production: 0 - {percentile_33:.2f} kW\")\nprint(f\"Medium production: {percentile_33:.2f} - {percentile_66:.2f} kW\")\nprint(f\"High production: {percentile_66:.2f}+ kW\")\n\n# Create class labels (0: Low, 1: Medium, 2: High)\ny = np.zeros(len(y_continuous))\ny[y_continuous > percentile_33] = 1\ny[y_continuous > percentile_66] = 2\n\nprint(f\"\\nClass distribution:\")\nunique, counts = np.unique(y, return_counts=True)\nfor cls, cnt in zip(unique, counts):\n    print(f\"  Class {int(cls)}: {cnt} samples ({100*cnt/len(y):.1f}%)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80-20 random split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train_norm = scaler.fit_transform(X_train)\n",
    "X_test_norm = scaler.transform(X_test)\n",
    "\n",
    "# Transpose for neural network format (features in rows, samples in columns)\n",
    "X_train_norm = X_train_norm.T\n",
    "X_test_norm = X_test_norm.T\n",
    "y_train = y_train.reshape(1, -1)\n",
    "y_test = y_test.reshape(1, -1)\n",
    "\n",
    "m_train = X_train_norm.shape[1]\n",
    "m_test = X_test_norm.shape[1]\n",
    "\n",
    "print(f\"Training samples: {m_train}\")\n",
    "print(f\"Test samples: {m_test}\")\n",
    "print(f\"X_train shape: {X_train_norm.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Building the Model\n",
    "\n",
    "### One-vs-Rest Strategy\n",
    "\n",
    "For multi-class classification, we train 3 binary classifiers (one per class) and select the class with highest probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Compute sigmoid activation\n",
    "    \"\"\"\n",
    "    s = 1 / (1 + np.exp(-z))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_with_zeros(dim):\n",
    "    \"\"\"\n",
    "    Initialize weights with zeros\n",
    "    \"\"\"\n",
    "    w = np.zeros((dim, 1))\n",
    "    b = 0.0\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward and Backward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate(w, b, X, Y):\n",
    "    \"\"\"\n",
    "    Compute cost and gradients\n",
    "    \"\"\"\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    # Forward propagation\n",
    "    A = sigmoid(np.dot(w.T, X) + b)\n",
    "    cost = -(1/m) * np.sum(Y * np.log(A + 1e-8) + (1 - Y) * np.log(1 - A + 1e-8))\n",
    "    \n",
    "    # Backward propagation\n",
    "    dw = (1/m) * np.dot(X, (A - Y).T)\n",
    "    db = (1/m) * np.sum(A - Y)\n",
    "    \n",
    "    cost = np.squeeze(np.array(cost))\n",
    "    grads = {\"dw\": dw, \"db\": db}\n",
    "    \n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(w, b, X, Y, num_iterations=2000, learning_rate=0.5, print_cost=False):\n",
    "    \"\"\"\n",
    "    Optimize weights using gradient descent\n",
    "    \"\"\"\n",
    "    w = copy.deepcopy(w)\n",
    "    b = copy.deepcopy(b)\n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        grads, cost = propagate(w, b, X, Y)\n",
    "        \n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        w = w - learning_rate * dw\n",
    "        b = b - learning_rate * db\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "            if print_cost:\n",
    "                print(f\"Cost after iteration {i}: {cost}\")\n",
    "    \n",
    "    params = {\"w\": w, \"b\": b}\n",
    "    grads = {\"dw\": dw, \"db\": db}\n",
    "    \n",
    "    return params, grads, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w, b, X):\n",
    "    \"\"\"\n",
    "    Predict probabilities\n",
    "    \"\"\"\n",
    "    m = X.shape[1]\n",
    "    w = w.reshape(X.shape[0], 1)\n",
    "    \n",
    "    A = sigmoid(np.dot(w.T, X) + b)\n",
    "    \n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete Model (One-vs-Rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_multiclass(X_train, y_train, X_test, y_test, num_classes=3, \n",
    "                     num_iterations=1000, learning_rate=0.5, print_cost=False):\n",
    "    \"\"\"\n",
    "    Train one-vs-rest classifiers for multi-class classification\n",
    "    \"\"\"\n",
    "    dim = X_train.shape[0]\n",
    "    models = []\n",
    "    \n",
    "    # Train one classifier per class\n",
    "    for c in range(num_classes):\n",
    "        print(f\"\\n--- Training classifier for class {c} ---\")\n",
    "        \n",
    "        # Create binary labels (1 if class c, 0 otherwise)\n",
    "        y_binary = (y_train == c).astype(float)\n",
    "        \n",
    "        # Initialize and optimize\n",
    "        w, b = initialize_with_zeros(dim)\n",
    "        params, grads, costs = optimize(w, b, X_train, y_binary, \n",
    "                                       num_iterations, learning_rate, print_cost)\n",
    "        \n",
    "        models.append({\"w\": params[\"w\"], \"b\": params[\"b\"], \"costs\": costs})\n",
    "    \n",
    "    # Predict on train and test sets\n",
    "    train_probs = np.zeros((num_classes, X_train.shape[1]))\n",
    "    test_probs = np.zeros((num_classes, X_test.shape[1]))\n",
    "    \n",
    "    for c in range(num_classes):\n",
    "        train_probs[c, :] = predict(models[c][\"w\"], models[c][\"b\"], X_train)\n",
    "        test_probs[c, :] = predict(models[c][\"w\"], models[c][\"b\"], X_test)\n",
    "    \n",
    "    # Select class with highest probability\n",
    "    y_pred_train = np.argmax(train_probs, axis=0).reshape(1, -1)\n",
    "    y_pred_test = np.argmax(test_probs, axis=0).reshape(1, -1)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    train_acc = 100 * np.mean(y_pred_train == y_train)\n",
    "    test_acc = 100 * np.mean(y_pred_test == y_test)\n",
    "    \n",
    "    print(f\"\\nTraining accuracy: {train_acc:.2f}%\")\n",
    "    print(f\"Test accuracy: {test_acc:.2f}%\")\n",
    "    \n",
    "    return {\n",
    "        \"models\": models,\n",
    "        \"y_pred_train\": y_pred_train,\n",
    "        \"y_pred_test\": y_pred_test,\n",
    "        \"train_accuracy\": train_acc,\n",
    "        \"test_accuracy\": test_acc\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model_multiclass(X_train_norm, y_train, X_test_norm, y_test,\n",
    "                         num_classes=3, num_iterations=1000, \n",
    "                         learning_rate=0.5, print_cost=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Results Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curves for each classifier\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for c in range(3):\n",
    "    costs = result['models'][c]['costs']\n",
    "    axes[c].plot(costs)\n",
    "    axes[c].set_title(f'Class {c} Learning Curve')\n",
    "    axes[c].set_xlabel('Iterations (x100)')\n",
    "    axes[c].set_ylabel('Cost')\n",
    "    axes[c].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "Shows how well the model distinguishes between production levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from sklearn.metrics import confusion_matrix\n\n# Compute confusion matrix (ensure all 3 classes are represented)\ncm = confusion_matrix(y_test.flatten(), result['y_pred_test'].flatten(), labels=[0, 1, 2])\n\n# Plot using matplotlib\nfig, ax = plt.subplots(figsize=(8, 6))\nim = ax.imshow(cm, cmap='Blues')\n\n# Add colorbar\nplt.colorbar(im, ax=ax)\n\n# Set ticks and labels\nclass_labels = ['Low', 'Medium', 'High']\nax.set_xticks(np.arange(len(class_labels)))\nax.set_yticks(np.arange(len(class_labels)))\nax.set_xticklabels(class_labels)\nax.set_yticklabels(class_labels)\n\n# Add text annotations\nfor i in range(len(class_labels)):\n    for j in range(len(class_labels)):\n        text = ax.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"black\")\n\nax.set_title('Confusion Matrix - Test Set')\nax.set_ylabel('True Class')\nax.set_xlabel('Predicted Class')\nplt.show()\n\nprint(\"\\nConfusion Matrix:\")\nprint(cm)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from sklearn.metrics import classification_report\n\nprint(classification_report(y_test.flatten(), result['y_pred_test'].flatten(),\n                          target_names=['Low', 'Medium', 'High'],\n                          labels=[0, 1, 2],\n                          zero_division=0))"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}